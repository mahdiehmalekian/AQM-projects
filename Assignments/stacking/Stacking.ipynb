{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w (X_train, y_train, X_test, classifiers, probability=False):\n",
    "    \"\"\"Trains different models using classifiers in \"classifiers\" on X_train, y_train, and builds w_train and w_test\"\"\"\n",
    "    \"\"\"If probability=True, it uses classifier.predict_proba\"\"\"\n",
    "    \n",
    "    w_train, w_test = None, None\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        if probability:\n",
    "            y_pred_train = clf.predict_proba (X_train)[:, 0]\n",
    "            y_pred_test = clf.predict_proba (X_test)[:, 0]\n",
    "        else:    \n",
    "            y_pred_train = clf.predict (X_train)\n",
    "            y_pred_test = clf.predict (X_test)\n",
    "        \n",
    "        y_pred_train = np.reshape (y_pred_train, (-1, 1))\n",
    "        y_pred_test = np.reshape (y_pred_test, (-1, 1))\n",
    "        \n",
    "        if w_train is None:\n",
    "            w_train = y_pred_train\n",
    "            w_test = y_pred_test\n",
    "        else:\n",
    "            w_train = np.concatenate ((w_train, y_pred_train), axis=1)\n",
    "            w_test = np.concatenate ((w_test, y_pred_test), axis=1)\n",
    "            \n",
    "    return (w_train, w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_metrics (clf, X_train, y_train, X_test, y_test, probability=False):\n",
    "    \"\"\"\"Gives confusion matrix and f1_score obtained from having a classifier (clf) employ \"w\" to predict y_test\"\"\"\n",
    "    \"\"\"It passes \"probability\" to get_w\"\"\"\n",
    "    \n",
    "    classifiers = [LinearDiscriminantAnalysis(), LogisticRegression(), svm.SVC(probability=True), tree.DecisionTreeClassifier()]\n",
    "    w_train, w_test = get_w (X_train, y_train, X_test, classifiers, probability=probability)\n",
    "\n",
    "    clf.fit(w_train, y_train)\n",
    "    y_pred_test = clf.predict(w_test)\n",
    "    \n",
    "    #print ('confusion matrix ,f1 score')\n",
    "    return (confusion_matrix(y_test, y_pred_test), f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_w_metrics on Breast Cancer data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply our code to the breast cancer data using a couple classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "dataset = pd.read_csv('./BreastCancer.csv')\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "X_columns = np.r_[1:6, 8:10]\n",
    "# x_columns = np.r_[1:10]\n",
    "X = dataset.iloc[:, X_columns].values \n",
    "y = dataset.iloc[:, len(dataset.columns) - 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "0 th\n",
      "split of data into training and testing\n",
      "************************************************************************\n",
      "LDA -------------------------\n",
      "(array([[47,  3],\n",
      "       [ 1, 18]], dtype=int64), 0.9)\n",
      "---------------------------\n",
      "\n",
      "LR -------------------------\n",
      "(array([[47,  3],\n",
      "       [ 1, 18]], dtype=int64), 0.9)\n",
      "---------------------------\n",
      "\n",
      "SVM -------------------------\n",
      "(array([[47,  3],\n",
      "       [ 2, 17]], dtype=int64), 0.8717948717948718)\n",
      "---------------------------\n",
      "\n",
      "DT -------------------------\n",
      "(array([[47,  3],\n",
      "       [ 2, 17]], dtype=int64), 0.8717948717948718)\n",
      "---------------------------\n",
      "\n",
      "************************************************************************\n",
      "1st\n",
      "split of data into training and testing\n",
      "************************************************************************\n",
      "LDA -------------------------\n",
      "(array([[38,  3],\n",
      "       [ 2, 26]], dtype=int64), 0.912280701754386)\n",
      "---------------------------\n",
      "\n",
      "LR -------------------------\n",
      "(array([[38,  3],\n",
      "       [ 2, 26]], dtype=int64), 0.912280701754386)\n",
      "---------------------------\n",
      "\n",
      "SVM -------------------------\n",
      "(array([[38,  3],\n",
      "       [ 2, 26]], dtype=int64), 0.912280701754386)\n",
      "---------------------------\n",
      "\n",
      "DT -------------------------\n",
      "(array([[38,  3],\n",
      "       [ 2, 26]], dtype=int64), 0.912280701754386)\n",
      "---------------------------\n",
      "\n",
      "************************************************************************\n",
      "2nd\n",
      "split of data into training and testing\n",
      "************************************************************************\n",
      "LDA -------------------------\n",
      "(array([[52,  2],\n",
      "       [ 3, 12]], dtype=int64), 0.8275862068965518)\n",
      "---------------------------\n",
      "\n",
      "LR -------------------------\n",
      "(array([[53,  1],\n",
      "       [ 2, 13]], dtype=int64), 0.896551724137931)\n",
      "---------------------------\n",
      "\n",
      "SVM -------------------------\n",
      "(array([[53,  1],\n",
      "       [ 3, 12]], dtype=int64), 0.8571428571428571)\n",
      "---------------------------\n",
      "\n",
      "DT -------------------------\n",
      "(array([[53,  1],\n",
      "       [ 2, 13]], dtype=int64), 0.896551724137931)\n",
      "---------------------------\n",
      "\n",
      "************************************************************************\n",
      "3rd\n",
      "split of data into training and testing\n",
      "************************************************************************\n",
      "LDA -------------------------\n",
      "(array([[43,  2],\n",
      "       [ 0, 24]], dtype=int64), 0.9600000000000001)\n",
      "---------------------------\n",
      "\n",
      "LR -------------------------\n",
      "(array([[43,  2],\n",
      "       [ 0, 24]], dtype=int64), 0.9600000000000001)\n",
      "---------------------------\n",
      "\n",
      "SVM -------------------------\n",
      "(array([[43,  2],\n",
      "       [ 0, 24]], dtype=int64), 0.9600000000000001)\n",
      "---------------------------\n",
      "\n",
      "DT -------------------------\n",
      "(array([[43,  2],\n",
      "       [ 0, 24]], dtype=int64), 0.9600000000000001)\n",
      "---------------------------\n",
      "\n",
      "************************************************************************\n",
      "4 th\n",
      "split of data into training and testing\n",
      "************************************************************************\n",
      "LDA -------------------------\n",
      "(array([[48,  2],\n",
      "       [ 2, 17]], dtype=int64), 0.8947368421052632)\n",
      "---------------------------\n",
      "\n",
      "LR -------------------------\n",
      "(array([[48,  2],\n",
      "       [ 4, 15]], dtype=int64), 0.8333333333333333)\n",
      "---------------------------\n",
      "\n",
      "SVM -------------------------\n",
      "(array([[48,  2],\n",
      "       [ 5, 14]], dtype=int64), 0.7999999999999999)\n",
      "---------------------------\n",
      "\n",
      "DT -------------------------\n",
      "(array([[48,  2],\n",
      "       [ 4, 15]], dtype=int64), 0.8333333333333333)\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LinearDiscriminantAnalysis(), LogisticRegression(), svm.SVC(probability=True), tree.DecisionTreeClassifier()]\n",
    "num_tries = 5\n",
    "for i in range (num_tries):\n",
    "    print ('************************************************************************')\n",
    "    if i == 1: print ('1st',)\n",
    "    elif i == 2: print ('2nd',)\n",
    "    elif i == 3: print ('3rd',)\n",
    "    else: print (i,'th',)\n",
    "    print ('split of data into training and testing')\n",
    "    print ('************************************************************************')\n",
    "    # Splitting data in training and test set\n",
    "    test_size = 0.1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    for j in range(len(classifiers)):\n",
    "        clf = classifiers[j]\n",
    "        if j == 0: print ('LDA -------------------------')\n",
    "        elif j == 1: print ('LR -------------------------')\n",
    "        elif j == 2: print ('SVM -------------------------')\n",
    "        elif j == 3: print ('DT -------------------------')\n",
    "        print(get_w_metrics (clf, X_train, y_train, X_test, y_test))\n",
    "        print ( '---------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few mistakes in predicting y_test! Stacking does an amazing job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does balancing data and/or using probability for classification help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to see if balancing the data set improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(df, target):\n",
    "    \"\"\"Gives a balanced data set of a multi-class dataset by adding a random sample of under-represented classes\"\"\"\n",
    "    \"\"\"Assumes df is a pandas series\"\"\"\n",
    "    \n",
    "    df_b = df.copy(deep=True)\n",
    "\n",
    "    max_freq = df[target].value_counts().max()\n",
    "    \n",
    "    for i in df[target].unique():\n",
    "        df_i = df[df[target] == i]\n",
    "        \n",
    "        needed_i = max_freq - len(df_i)\n",
    "        to_add = df_i.sample(n=needed_i)\n",
    "        \n",
    "        df_b = pd.concat([df_b,to_add])\n",
    "\n",
    "    return df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_f1_score (X, y, clf, probability=False, num_tries=100):\n",
    "    \n",
    "    f1_score_sum = 0\n",
    "    \n",
    "    for i in range (num_tries):\n",
    "        # Splitting data in training and test set\n",
    "        test_size = 0.1\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        f1_score_sum += get_w_metrics (clf, X_train, y_train, X_test, y_test, probability=probability)[1]\n",
    "\n",
    "    return f1_score_sum/num_tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA -------------------------\n",
      "average F1 on original dataset vs. balanced dataset when probaility=False\n",
      "0.93, 0.97\n",
      "average F1 on original dataset vs. balanced dataset when probaility=True\n",
      "0.93, 0.97\n",
      "---------------------------\n",
      "\n",
      "LR -------------------------\n",
      "average F1 on original dataset vs. balanced dataset when probaility=False\n",
      "0.91, 0.97\n",
      "average F1 on original dataset vs. balanced dataset when probaility=True\n",
      "0.91, 0.97\n",
      "---------------------------\n",
      "\n",
      "SVM -------------------------\n",
      "average F1 on original dataset vs. balanced dataset when probaility=False\n",
      "0.91, 0.96\n",
      "average F1 on original dataset vs. balanced dataset when probaility=True\n",
      "0.91, 0.97\n",
      "---------------------------\n",
      "\n",
      "DT -------------------------\n",
      "average F1 on original dataset vs. balanced dataset when probaility=False\n",
      "0.92, 0.96\n",
      "average F1 on original dataset vs. balanced dataset when probaility=True\n",
      "0.92, 0.97\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LinearDiscriminantAnalysis(), LogisticRegression(), svm.SVC(probability=True), tree.DecisionTreeClassifier()]\n",
    "\n",
    "# Construct X, y\n",
    "X = dataset.iloc[:, X_columns].values \n",
    "y = dataset.iloc[:, len(dataset.columns) - 1].values\n",
    "\n",
    "# Construct X_b, y_b\n",
    "dataset_b = balance (dataset, 'Class')\n",
    "X_b = dataset_b.iloc[:, X_columns].values \n",
    "y_b = dataset_b.iloc[:, len(dataset_b.columns) - 1].values\n",
    "\n",
    "for j in range(len(classifiers)):\n",
    "    clf = classifiers[j]\n",
    "    if j == 0: print ('LDA -------------------------')\n",
    "    elif j == 1: print ('LR -------------------------')\n",
    "    elif j == 2: print ('SVM -------------------------')\n",
    "    elif j == 3: print ('DT -------------------------')\n",
    "    print ('average F1 on original dataset vs. balanced dataset when probaility=False')\n",
    "    print (\"%.2f, %.2f\" % (avg_f1_score(X, y, clf), avg_f1_score(X_b, y_b, clf)))\n",
    "    print ('average F1 on original dataset vs. balanced dataset when probaility=True')\n",
    "    print (\"%.2f, %.2f\" % (avg_f1_score(X, y, clf, probability=True), avg_f1_score(X_b, y_b, clf, probability=True)))    \n",
    "    print ( '---------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all cases, F1 on balanced dataset is higher, however using probability in classification doesn't significantly improve F1-score.\n",
    "Perhaps a plot would be nice here...!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
